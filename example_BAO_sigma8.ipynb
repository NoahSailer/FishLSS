{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: BAO and $\\sigma_8(z)$ forecasts\n",
    "\n",
    "\n",
    "$\\verb|FishLSS|$ requires $\\verb|velocileptors|$ to run, which can be installed with: `python3 -m pip install -v git+https://github.com/sfschen/velocileptors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import revelant packages\n",
    "from headers import *\n",
    "from twoPoint import *\n",
    "from twoPointNoise import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Setting up a $\\verb|FishLSS|$ forecast\n",
    "\n",
    "### (1a) The cosmology\n",
    "\n",
    "A $\\verb|FishLSS|$ forecast requires two main ingredients: a fiducial cosmology and an experiment. For the input cosmology, we use a $\\verb|CLASS|$ object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'output': 'tCl lCl mPk',\n",
    "          'l_max_scalars': 1000,\n",
    "          'lensing': 'yes',\n",
    "          'P_k_max_h/Mpc': 2.,\n",
    "          'non linear':'halofit', \n",
    "          'z_pk': '0.0,6',\n",
    "          'A_s': 2.10732e-9,\n",
    "          'n_s': 0.96824,\n",
    "          'alpha_s': 0.,\n",
    "          'h': 0.6770,\n",
    "          'N_ur': 1.0196,\n",
    "          'N_ncdm': 2,\n",
    "          'm_ncdm': '0.01,0.05',\n",
    "          'tau_reio': 0.0568,\n",
    "          'omega_b': 0.02247,\n",
    "          'omega_cdm': 0.11923,\n",
    "          'Omega_k': 0.}\n",
    "\n",
    "cosmo = Class() \n",
    "cosmo.set(params) \n",
    "cosmo.compute() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1b) The experiment\n",
    "\n",
    "Now we specify the experiment, which is an instance of $\\verb|experiment.py|$. At a minimum, we need to specify the redshift range of the survey ($z_\\text{min}$ and $z_\\text{max}$), the redshift binning, the sky coverage $f_\\text{sky}$, the linear bias $b(z)$, and the number density $\\bar{n}(z)$. The redshift binning can be specified in two ways: you can either input a `zedges` (numpy array) to specify the edges of the bins, or `nbins` (integer), in which case the redshift bins are assumed to be linearly spaced in $z$. Here we set `nbins = 3` for simplicity, so that we have three redshift bins with $\\Delta z=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal set of inputs to an experiment object\n",
    "zmin = 2.\n",
    "zmax = 5.\n",
    "nbins = 3\n",
    "fsky = 0.5\n",
    "b = lambda z: (1+z) \n",
    "n = lambda z: 3e-4 * np.exp(-(z-3.5)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiment(zmin=zmin, zmax=zmax, nbins=nbins, fsky=fsky, b=b, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the above, one can optionally specify the following in an `experiment` object.\n",
    "\n",
    "- `b2` (function of $z$): quadratic bias $b_2(z)$ of the tracer, default $b_2 = 8(b-1)/21$\n",
    "- `sigv` (float): the comoving velocity dispersion for FoG contributions [km/s], default is 100 km/s\n",
    "- `sigma_z` (float): redshift error $\\sigma_z/(1+z)$, assumed to be independent of redshift, default is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1c) The forecast object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a cosmology and an experiment in hand, we can now create a forecast. Running the line below will create an `output` directory, as well as a subdirectory for the experiment of interest: `output/example` in this case. After creating these directories, $\\verb|FishLSS|$ will calculate the fiducial power spectra ($P_{gg}(\\boldsymbol{k},z)$ and $P_\\text{recon}(\\boldsymbol{k},z)$) at the center of each redshift bin, and store them in `output/example/derivatives/` and `output/example/derivatives_recon` respectively (assuming that the files don't already exist). $\\verb|FishLSS|$ will also calculate $C^{\\kappa\\kappa}_\\ell$, $C^{\\kappa g_i}_\\ell$ and $C^{g_i g_i}_\\ell$ for each redshift bin, and save them in `output/example/derivatives_Cl`. \n",
    "\n",
    "Calculating the fiducial power spectra takes a little while ($\\sim 10$ minutes for $3$ redshift bins), so go grab some coffee..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = fisherForecast(experiment=exp,cosmo=cosmo,name='example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redshift-space power spectra are computed on a (flattened) $k-\\mu$ grid. That is, $P_{gg}(\\boldsymbol{k},z)$ is stored as an array of length `forecast.Nk * forecast.Nmu`, with the corresponding values of $k$ and $\\mu$ stored in `forecast.k` and `forecast.mu`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) BAO forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in $\\S3.6$ of [2106.09713](https://arxiv.org/pdf/2106.09713.pdf), we hold the shape of the fiducial power spectrum fixed in our BAO forecasts. We then find the errors on the two A-P parameters ($\\alpha_\\perp$, $\\alpha_\\parallel$) after marginalizing over the linear bias $b$ and 15 broad-band polynomials $\\sum_{n=0}^4\\sum_{m=0}^2 c_{nm}k^n\\mu^{2m}$. We finally intepret the errors on the A-P parameters as the relative errors of $D_A(z)/r_d$ and $H(z)r_d$, where $r_d$ is sound horizon at the drag epoch.\n",
    "\n",
    "Marginalizing over the polynomial coefficients is trivial to do analytically, so we only need to numerically compute derivatives with respect to $\\alpha_\\perp,\\alpha_\\parallel$ and $b$. Calculating these derivatives will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = np.array(['alpha_perp','alpha_parallel','b'])\n",
    "\n",
    "# set recon = True, so that we perform BAO reconstruction when computing the power spectrum\n",
    "forecast.recon = True\n",
    "\n",
    "# set the \"marginalized parameters\", aka the derivatives, to be [alpha's, linear b]\n",
    "forecast.marg_params = basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the derivatives in each redshift bin (evaluated at the midpoint of each bin)\n",
    "forecast.compute_derivatives()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivatives have been automatically stored in `output/example/derivatives_recon`. To load these derivatives, simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivs = forecast.load_derivatives(basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the Fisher matrices in each redshift bin using `get_fisher`, which takes the arguments:\n",
    "\n",
    "- `basis` (np array): basis of the Fisher matrix \n",
    "- `globe` (int): let's not worry about this for now, it's value isn't important for computing the Fisher matrix for a single redshift bin\n",
    "- `derivatives` (np array): load the derivatives from memory, if not specificied $\\verb|FishLSS|$ will recalculate them (takes a lot of time!)\n",
    "- `zbins` (np array): an array of ints specifying which redshift bins to include in the Fisher matrix. In this case we're computing a Fisher matrix for each redshift bin, so we set `zbins = np.array([i])` to get the Fisher matrix for the i'th bin.\n",
    "\n",
    "In addition the the above you can also specify `kmax` or `kmax_knl` (ratio of $k_\\text{max}$ to the non-linear scale at the center of each redshift bin). By default we set `kmax_knl=1` and `kmax=-10`. If `kmax` is set to be a positive number, then the code ignores `kmax_knl` and uses `kmax` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the fisher matrices in each of the 3 redshift bins\n",
    "F = lambda i: forecast.gen_fisher(basis, 100, derivatives=derivs, zbins=np.array([i]))\n",
    "Fs = [F(i) for i in range(nbins)]\n",
    "Fs = np.array(Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we set `recon = True` when computing the Fisher matrices, $\\verb|FishLSS|$ automatically knows to marginalize over the 15 polynomials, so each Fisher matrix will be an $18\\times18$ matrix with basis $\\{\\alpha_\\perp,\\alpha_\\parallel,b,c_{00},\\cdots\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 18, 18)\n"
     ]
    }
   ],
   "source": [
    "print(Fs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets invert and compute the errors on the A-P parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finvs = [np.linalg.inv(Fs[i]) for i in range(nbins)]\n",
    "saperp = [np.sqrt(Finvs[i][0,0]) for i in range(nbins)]\n",
    "saparr = [np.sqrt(Finvs[i][1,1]) for i in range(nbins)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From which we get the relative error on $D_A(z)/r_d$ and $H(z)r_d$ in each redshift bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error on DA/rd: [0.003181433656693976, 0.001842152405859197, 0.003276545170228536]\n",
      "Relative error on H*rd: [0.004565731326440649, 0.0028150515717583935, 0.004831631731011703]\n"
     ]
    }
   ],
   "source": [
    "print('Relative error on DA/rd:',saperp)\n",
    "print('Relative error on H*rd:',saparr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done with BAO forecasting, so let's set `recon = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.recon = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) $\\sigma_8(z)$ forecast\n",
    "\n",
    "### (3a) From full-shape data only\n",
    "\n",
    "#### Derived from $\\Lambda$CDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll compute the relative error on $\\sigma_8(z)$ in each of the three redshift bins, following the methods described in $\\S4.3$ of [2106.09713](https://arxiv.org/pdf/2106.09713.pdf). First we have to compute the relevant derivatives of the full shape power spectrum. This takes an hour-ish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = np.array(['h','log(A_s)','n_s','omega_cdm','omega_b','tau_reio',\n",
    "                  'N','alpha0','b','b2','bs','N2','N4','alpha2','alpha4'])\n",
    "\n",
    "forecast.marg_params = basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.compute_derivatives()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = forecast.load_derivatives(basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compute the Fisher matrices in each bin, which has a 15-dimensional basis $$\\{h,\\ln(A_s),n_s,\\omega_c,\\omega_b,\\tau,N_0(z_i),\\alpha_0(z_i),b(z_i),b_2(z_i),b_s(z_i),N_2(z_i),N_4(z_i),\\alpha_2(z_i),\\alpha_4(z_i)\\}$$\n",
    "The order that I chose for the nuisance terms in this basis might seem odd to you, but this will become more clear when combining full shape information with CMB lensing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = lambda i: forecast.gen_fisher(basis,100,kmax_knl=1.,derivatives=derivatives, zbins = np.array([i]))\n",
    "Fs = np.array([F(i) for i in range(nbins)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to add a Gaussian prior on $\\omega_b$ from BBN. We do this using the `combine_fishers` function, which takes the following inputs:\n",
    "\n",
    "- a list of fisher matrices (they don't all have to be the same dimension)\n",
    "- `globe` (int): Let $\\{a_1,\\cdots,a_n,b_1,\\cdots,b_m\\}$ be the basis of the first Fisher matrix and $\\{a_1,\\cdots,a_n,c_1,\\cdots,c_l\\}$ be the basis of the second Fisher matrix, where I'm assuming that the $b_i$'s and $c_i$'s are distinct parameters (such as two different sets of nuisance parameters), then `globe = n`. That is, `globe` counts the number of \"global\" parameters that are common to the Fisher matrices. In this case we are combining a $6\\times 6$ Fisher with a $15\\times 15$ Fisher, with the first six parameters being the same $\\Lambda$CDM parameters for both Fishers. So for this case we set `globe = 6`. <span style=\"color:red\"> This function assumes that the Fishers have the same basis up to the globe'th entry. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBN_prior = np.array([0,0,0,0,(5e-4)**(-2),0])\n",
    "BBN_prior = np.diag(BBN_prior)\n",
    "\n",
    "for i in range(nbins): Fs[i] = forecast.combine_fishers([Fs[i],BBN_prior],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to rotate from the basis $\\{h,\\ln(A_s),n_s,\\omega_\\text{cdm},\\omega_b,\\tau,\\cdots\\}$ to $\\{\\sigma_8(z_i),\\ln(A_s),n_s,\\omega_\\text{cdm},\\omega_b,\\tau,\\cdots\\}$, where $z_i$ is the central redshift in the i'th redshift bin. To do this we need to compute the rotation matrix, which we do using the `rotation_matrix` helper function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldbasis = np.array(['h','log(A_s)','n_s','omega_cdm','omega_b','tau_reio'])\n",
    "\n",
    "def s8(z):\n",
    "   s8 = cosmo.sigma(8/params['h'],z)\n",
    "   return s8 \n",
    "\n",
    "def ds8dp(param,z):\n",
    "   flag = False\n",
    "   if param == 'h' or param == 'n_s' or param == 'omega_cdm' or param == 'omega_b' or param == 'tau_reio' or param =='log(A_s)':\n",
    "      if param == 'log(A_s)':\n",
    "         flag = True\n",
    "         param = 'A_s'\n",
    "      fid_val = params[param]\n",
    "      fid_fs8 = s8(z)\n",
    "      cosmo.set({param: fid_val*1.01})\n",
    "      cosmo.compute()\n",
    "      new_fs8 = s8(z)\n",
    "      cosmo.set({param: fid_val})\n",
    "      cosmo.compute()\n",
    "      if flag: return params[param]*(new_fs8-fid_fs8)/fid_val/0.01\n",
    "      return (new_fs8-fid_fs8)/fid_val/0.01\n",
    "   else: return 0\n",
    "\n",
    "def rotation_matrix(z,n):\n",
    "   result = np.zeros((n,n))\n",
    "   for i in range(n):\n",
    "      for j in range(n):\n",
    "         if i != 0 and i == j: result[i,j] = 1\n",
    "         if i == 0 and j<len(oldbasis): result[i,j] = ds8dp(oldbasis[j],z)\n",
    "   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the rotation matrices for each of the three redshift bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs_example = np.array([rotation_matrix(z,n=15) for z in forecast.experiment.zcenters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper function to do the rotation, and to get the relative constraints on $\\sigma_8(z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_s8_constraint(Fs,Rs):\n",
    "   con = np.zeros(len(Rs)) # len(Rs) = number of redshift bins\n",
    "   for i in range(len(Rs)):\n",
    "      F = Fs[i] ; Rinv = np.linalg.inv(Rs[i])\n",
    "      Fprime = np.dot(np.dot(Rinv.T,F),Rinv) # rotate to new basis\n",
    "      Cprime = np.linalg.inv(Fprime)\n",
    "      zi = forecast.experiment.zcenters[i]\n",
    "      con[i] = np.sqrt(Cprime[0,0])/s8(zi) # get constraint on sigma8(z)\n",
    "   return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative constraints on sigma8(z) (derived from LCDM): [0.01912116 0.0148741  0.02459258]\n"
     ]
    }
   ],
   "source": [
    "s8_constraints = get_rel_s8_constraint(Fs,Rs_example)\n",
    "print('Relative constraints on sigma8(z) (derived from LCDM):',s8_constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed shape\n",
    "\n",
    "Now we are going to get the errors on $\\sigma_8(z)$ assuming that the shape of the power spectrum is fixed. In this case $\\sigma_8^2\\propto A_s$ is entirely determined by the primordial amplitude $A_s$. At the level of derivatives this implies $\\partial_{\\ln \\sigma_8(z)} = 2\\partial_{\\ln A_s}$, so the relative error on $\\sigma_8(z)$ is half the relative error on $A_s$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_fixed = np.array(['log(A_s)','N','alpha0','b','b2','bs','N2','N4','alpha2','alpha4'])\n",
    "derivatives_fixed = forecast.load_derivatives(basis_fixed)\n",
    "\n",
    "F_fix = lambda i: forecast.gen_fisher(basis_fixed,100,kmax_knl=1.,\n",
    "                derivatives=derivatives_fixed, zbins = np.array([i]))\n",
    "\n",
    "Fs_fixed = np.array([F_fix(i) for i in range(nbins)])\n",
    "Finvs_fixed = np.array([np.linalg.inv(Fs_fixed[i]) for i in range(nbins)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative constraints on sigma8(z) (fixed shape): [0.01072835 0.00743769 0.01343389]\n"
     ]
    }
   ],
   "source": [
    "def get_s8_constraint(i): return np.sqrt(Finvs_fixed[i][0,0])/2 # divide by two to convert A -> s8\n",
    "s8_constraints_fixed = np.array([get_s8_constraint(i) for i in range(nbins)])\n",
    "\n",
    "print('Relative constraints on sigma8(z) (fixed shape):',s8_constraints_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3b) Computing CMB lensing $\\times$ galaxies Fisher matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to compute the relevant derivatives of $(C^{\\kappa\\kappa}_\\ell, C^{\\kappa g_i}_\\ell, C^{g_ig_i}_\\ell)$. Again, this will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_lensing = np.array(['h','log(A_s)','n_s','omega_cdm','omega_b','tau_reio',\\\n",
    "                          'N','alpha0','b','b2','bs','alphax'])\n",
    "forecast.marg_params = basis_lensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.compute_Cl_derivatives()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll compute the CMB lensing $\\times$ galaxies Fisher matrices in each bin using `gen_lensing_fisher`, which takes the following inputs:\n",
    "\n",
    "- `basis_lensing` (np array): the basis of the Fisher matrix\n",
    "- `globe_lensing` (np array): number of global parameters (parameters which don't depend on the redshift bin), in this case 6 ($\\Lambda$CDM)\n",
    "- `ell_min`, `ell_max` (ints): multipoles to include in the Fisher matrix\n",
    "- `bins` (np array): array of ints to specify which redshift bins to include in the Fisher matrix, default is to include all the redshift bins\n",
    "- `kk` (boolean): Set False to remove $C^{\\kappa\\kappa}_\\ell$ from the data vector, default is True\n",
    "- `CMB` (string): Choose from 'Planck', 'SO' or 'S4' to set lensing noise levels \n",
    "\n",
    "In our example, the lensing Fisher matrix will have basis $\\{h,\\ln(A_s),n_s,\\omega_c,\\omega_b,\\tau,N_0(z_1),\\cdots,N_0(z_n),\\alpha_0(z_1),\\cdots,\\alpha_0(z_n),b(z_1),\\cdots\\}$, where $z_i$ is the central redshift of the i'th bin. In this example $i=0,1,2$. This is true regardless of the `bins` input. However, if we're only including one redshift bin in our data vector, then our data is obviously insensitive to the nuisance parameters in the other bins. Thus when setting `bins = np.array([i])`, we can remove the $N_0(z_j),\\alpha_0(z_j),\\cdots$ ($j\\neq i$) columns/rows from the Fisher matrix (which are all zero), so that our basis becomes: \n",
    "$$\\{h,\\ln(A_s),n_s,\\omega_c,\\omega_b,\\tau,N_0(z_i),\\alpha_0(z_i),b(z_i),b_2(z_i),b_s(z_i),\\alpha_x(z_i)\\}$$\n",
    "Below is a helper function `get_lensing_fishers` which deletes these unnessecary rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lensing_fishers(cast):\n",
    "   globe_lensing = 6\n",
    "   # xs is a set of indicies telling me the relevant terms for the i'th redshift bin\n",
    "   xs = [list(range(6)) # LCDM\n",
    "         +\n",
    "         [int(6+0*nbins+i),int(6+1*nbins+i),int(6+2*nbins+i), # relevant nuisance terms (6 of them)\n",
    "          int(6+3*nbins+i),int(6+4*nbins+i),int(6+5*nbins+i)]\n",
    "         for i in range(nbins)]\n",
    "   Lensing = [forecast.gen_lensing_fisher(basis_lensing,globe_lensing,ell_min=30,ell_max=500,\n",
    "                                          bins=np.array([i]),kk=False,CMB='S4') for i in range(nbins)]\n",
    "   Short = [Lensing[i][xs[i]][:,xs[i]] for i in range(nbins)] # remove all off the irrelevant columns/rows\n",
    "   return np.array(Short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs_lensing = get_lensing_fishers(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3c) $\\sigma_8(z)$ constraints from full-shape and CMB lensing $\\times$ galaxies\n",
    "\n",
    "#### Derived from $\\Lambda$CDM\n",
    "\n",
    "The bases for our full-shape and CMB lensing $\\times$ galaxies Fishers are (for each individual redshift bin):\n",
    "\n",
    "$$\\text{Full-shape}=G + \\{N_2(z_i),N_4(z_i),\\alpha_2(z_i),\\alpha_4(z_i)\\}$$\n",
    "$$\\text{CMB lensing}\\times\\text{galaxies}=G + \\{\\alpha_x(z_i)\\}$$\n",
    "where $G$ (the global piece) is defined to be\n",
    "$$G = \\{h,\\ln(A_s),n_s,\\omega_c,\\omega_b,\\tau,N_0(z_i),\\alpha_0(z_i),b(z_i),b_2(z_i),b_s(z_i)\\}.$$\n",
    "To combine the two Fishers we can just use the `combine_fishers` function, with `globe = 11` (the size of $G$). We do this for the \"derived from $\\Lambda$CDM\" procedure in the bit of code below. The combined Fisher matrix has basis\n",
    "$$G + \\{N_2(z_i),N_4(z_i),\\alpha_2(z_i),\\alpha_4(z_i),\\alpha_x(z_i)\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs_combined = []\n",
    "for i in range(nbins): \n",
    "    fishers = [Fs[i],Fs_lensing[i]] # full-shape, CMB x galaxies\n",
    "    globe = 11\n",
    "    combined = forecast.combine_fishers(fishers,globe)\n",
    "    Fs_combined.append(combined)\n",
    "Fs_combined = np.array(Fs_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll be lazy and recompute the rotation matrices with the correct dimension (16)\n",
    "Rs_example = np.array([rotation_matrix(z,n=16) for z in forecast.experiment.zcenters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative constraints on sigma8(z) (derived from LCDM, w CMB lensing): [0.01383381 0.01084548 0.01756993]\n"
     ]
    }
   ],
   "source": [
    "s8_constraints_combined = get_rel_s8_constraint(Fs_combined,Rs_example)\n",
    "print('Relative constraints on sigma8(z) (derived from LCDM, w CMB lensing):',s8_constraints_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure here is nearly identical apart from the global piece $G$, which now doesn't contain $h,n_s,\\omega_c,\\omega_b,\\tau$ (in particular, we now set `globe = 6`). I'm using `xs` to remove the $h,n_s,\\omega_c,\\omega_b,\\tau$ rows/columns from `Fs_lensing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs_combined_fixed = []\n",
    "for i in range(nbins): \n",
    "    xs = [1,6,7,8,9,10,11]\n",
    "    fishers = [Fs_fixed[i],Fs_lensing[i][xs][:,xs]] # full-shape, CMBxgalaxies\n",
    "    globe = 6\n",
    "    combined = forecast.combine_fishers(fishers,globe)\n",
    "    Fs_combined_fixed.append(combined)\n",
    "Finvs_combined_fixed = np.array([np.linalg.inv(Fs_combined_fixed[i]) for i in range(nbins)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative constraints on sigma8(z) (fixed shape, w lensing): [0.00898109 0.00683269 0.01183671]\n"
     ]
    }
   ],
   "source": [
    "def get_s8_constraint(i): return np.sqrt(Finvs_combined_fixed[i][0,0])/2 # divide by two to convert A -> s8\n",
    "s8_constraints_combined_fixed = np.array([get_s8_constraint(i) for i in range(nbins)])\n",
    "\n",
    "print('Relative constraints on sigma8(z) (fixed shape, w lensing):',s8_constraints_combined_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
